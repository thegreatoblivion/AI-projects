file_name,loss,learning_rate,days,n_epochs,dataset,score,comments
testing,"tensor(0.2354, grad_fn=<MseLossBackward0>)",0.001,65,500,NVDA,,
65 days,"tensor(0.2354, grad_fn=<MseLossBackward1>)",0.001,66,500,NVDA,,accuracy aabout 5%
more,"tensor(0.1361, grad_fn=<MseLossBackward0>)",0.001,65,1000,NVDA,,loss is better?
129 day,"tensor(0.2208, grad_fn=<MseLossBackward0>)",0.001,129,2000,NVDA,,similiar to benchmark
129 day,"tensor(0.2208, grad_fn=<MseLossBackward0>)",0.001,129,2000,NVDA,0.3255,similiar to benchmark
129 day,"tensor(0.2238, grad_fn=<MseLossBackward0>)",0.001,129,5000,NVDA,0.36,similiar to benchmark
129 day,"tensor(0.1773, grad_fn=<MseLossBackward0>)",0.001,65,5000,NVDA,0.324,similiar to benchmark
long epoch 65 day,"tensor(0.1773, grad_fn=<MseLossBackward0>)",0.001,65,5000,NVDA,0.324,similiar to benchmark
long epoch 65 day,"tensor(0.4170, grad_fn=<MseLossBackward0>)",0.001,17,1000,NVDA,0.4025,similiar to benchmark
17 day long epoch,"tensor(0.4170, grad_fn=<MseLossBackward0>)",0.001,17,1000,NVDA,0.4025,similiar to benchmark
longest epoch ever,"tensor(0.3237, grad_fn=<MseLossBackward0>)",0.001,65,10000,NVDA,0.3895,took 7 bloody minutes
longest epoch ever,"tensor(0.3237, grad_fn=<MseLossBackward0>)",0.001,65,10000,NVDA,0.3895,took 7 bloody minutes
20240822-105228,"tensor(0.1564, grad_fn=<MseLossBackward0>)",0.001,65,10000,NVDA,0.34075,8 minutes for this?
20240826-120652,"tensor(0.2347, grad_fn=<MseLossBackward0>)",0.001,65,10000,NVDA,0.37625,8 minutes for this?
